{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moderate-authority",
   "metadata": {},
   "source": [
    "# LAB 7: Error analysis\n",
    "\n",
    "Objectives\n",
    "* Construct a  linear text classifier using SGDClassifier\n",
    "* Evaluate its performance and categorize the errors that it makes\n",
    "* Eaxmine model's coefficients and decision function values\n",
    "* Interpret model results using LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sticky-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-serbia",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coated-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\n",
    "    \"s3://ling583/lab7-train.parquet\", storage_options={\"anon\": True}\n",
    ")\n",
    "test = pd.read_parquet(\"s3://ling583/lab7-test.parquet\", storage_options={\"anon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "retained-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    exclude=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"],\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [t.norm_ for t in doc if not (t.is_space or t.is_punct or t.like_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relevant-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contrary-duplicate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78acf25107704da5a4c2f4b28b1d7f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19054 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080e9fb3ed9849bb902ed8aca552b146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mp.Pool() as p:\n",
    "    train[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(train[\"text\"]), chunksize=100))\n",
    "    test[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(test[\"text\"]), chunksize=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-boxing",
   "metadata": {},
   "source": [
    "The labels are: GPOL = domestic politics, GSPO = sports, GVIO = war/civil war, GJOB = labor issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "balanced-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPOL    7410\n",
       "GSPO    5639\n",
       "GVIO    3712\n",
       "GJOB    2293\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"topics\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-elevation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "olive-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "changed-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        GJOB       0.97      0.92      0.94       573\n",
      "        GPOL       0.94      0.95      0.94      1853\n",
      "        GSPO       1.00      0.99      0.99      1410\n",
      "        GVIO       0.90      0.91      0.90       928\n",
      "\n",
      "    accuracy                           0.95      4764\n",
      "   macro avg       0.95      0.94      0.95      4764\n",
      "weighted avg       0.95      0.95      0.95      4764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = make_pipeline(CountVectorizer(analyzer=identity), SGDClassifier())\n",
    "baseline.fit(train[\"tokens\"], train[\"topics\"])\n",
    "base_predicted = baseline.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-remains",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Hyperparameter search\n",
    "\n",
    "Find an optimal set of hyperparameters for a Tfidf+SGDClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "czech-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from logger import log_search\n",
    "from scipy.stats.distributions import loguniform, randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "august-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "statutory-garlic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34173</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.62 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:34173' processes=4 threads=4, memory=16.62 GB>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:34173\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "international-stuart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'lab-7' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"lab-7\")\n",
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity), TfidfTransformer(), SGDClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atomic-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 1.44 s, total: 11.5 s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 20),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-6, 1e-2),\n",
    "    },\n",
    "    n_iter=50,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-photographer",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compare optimized model to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pressing-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        GJOB       0.97      0.94      0.95       573\n",
      "        GPOL       0.94      0.97      0.95      1853\n",
      "        GSPO       1.00      0.99      1.00      1410\n",
      "        GVIO       0.92      0.90      0.91       928\n",
      "\n",
      "    accuracy                           0.96      4764\n",
      "   macro avg       0.96      0.95      0.95      4764\n",
      "weighted avg       0.96      0.96      0.96      4764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=5, max_df=0.75),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=1e-4),\n",
    ")\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fleet-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_f1 = f1_score(test[\"topics\"], base_predicted, average=\"macro\")\n",
    "sgd_f1 = f1_score(test[\"topics\"], predicted, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "confused-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9463167933227535, 0.9543078380635164, 0.007991044740762843)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_f1, sgd_f1, sgd_f1 - base_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stable-gazette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1488555776633558"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sgd_f1 - base_f1) / (1 - base_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "going-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test, wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "copyrighted-chest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 44, 4639)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = (predicted == test[\"topics\"]).astype(int) - (\n",
    "    base_predicted == test[\"topics\"]\n",
    ").astype(int)\n",
    "sum(diff == 1), sum(diff == -1), sum(diff == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "honey-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005962486102612331"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_test([sum(diff == 1), sum(diff == -1)], alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "architectural-castle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=5103.0, pvalue=0.00046751317631981267)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon(diff, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-ottawa",
   "metadata": {},
   "source": [
    "**TO DO:** Summarize your results: how much better is the optimized model? Is it significantly better than the baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-neutral",
   "metadata": {},
   "source": [
    "The optimized model is much better than the baseline by a huge amount, as the macro average f1-score for the optimized model is 0.03 greater than the baselines, which is a significant amount, especially compared to the video where the difference was 0.01. In addition, the binomial and wilcoxon test p-values are very small, indicating that there is a difference, assuming the alpha is 0.05. Also the p-values were much smaller than ones in the video as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-mandate",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "angry-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "isolated-burden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        GJOB       0.98      0.93      0.95       573\n",
      "        GPOL       0.94      0.96      0.95      1853\n",
      "        GSPO       1.00      0.99      1.00      1410\n",
      "        GVIO       0.92      0.91      0.92       928\n",
      "\n",
      "    accuracy                           0.96      4764\n",
      "   macro avg       0.96      0.95      0.95      4764\n",
      "weighted avg       0.96      0.96      0.96      4764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(preprocessor=identity, tokenizer=tokenize, min_df=5, max_df=0.75),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=1e-4),\n",
    ")\n",
    "sgd.fit(train[\"text\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"text\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "civil-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudpickle.dump(sgd, open(\"sgd.model\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-universe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
